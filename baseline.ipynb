{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split training and test sets of transcription ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def flatten(list_of_list):\n",
    "    return [item for sublist in list_of_list for item in sublist]\n",
    "\n",
    "path_to_training = Path(\"training\")\n",
    "path_to_test = Path(\"test\")\n",
    "\n",
    "def split_dataset(validate=False):\n",
    "    training_set = ['ES2002', 'ES2005', 'ES2006', 'ES2007', 'ES2008', 'ES2009', 'ES2010', 'ES2012', 'ES2013', 'ES2015', 'ES2016', 'IS1000', 'IS1001', 'IS1002', 'IS1003', 'IS1004', 'IS1005', 'IS1006', 'IS1007', 'TS3005', 'TS3008', 'TS3009', 'TS3010', 'TS3011', 'TS3012']\n",
    "    training_set = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in training_set])\n",
    "    training_set.remove('IS1002a')\n",
    "    training_set.remove('IS1005d')\n",
    "    training_set.remove('TS3012c')\n",
    "\n",
    "    test_set = ['ES2003', 'ES2004', 'ES2011', 'ES2014', 'IS1008', 'IS1009', 'TS3003', 'TS3004', 'TS3006', 'TS3007']\n",
    "    test_set = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in test_set])\n",
    "    \n",
    "    if validate:\n",
    "        # randomly select 10% of training set as validation set\n",
    "        import random\n",
    "        random.seed(6969)\n",
    "        validate_set = random.choices(training_set, k=int(len(training_set)*0.1))\n",
    "        training_set = list(set(training_set) - set(validate_set))\n",
    "        return training_set, validate_set, test_set\n",
    "\n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions to get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import networkx as nx\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def get_text_feature(dataset, path, show_progress_bar=True):\n",
    "    text_feature = []\n",
    "    for transcription_id in dataset:\n",
    "        with open(path / f\"{transcription_id}.json\", \"r\") as text_file:\n",
    "            transcription = json.load(text_file)\n",
    "        \n",
    "        for utterance in transcription:\n",
    "            text_feature.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "\n",
    "    text_feature = bert.encode(text_feature, show_progress_bar=show_progress_bar)\n",
    "    return text_feature\n",
    "\n",
    "\n",
    "def get_graph_feature(dataset, path):\n",
    "    graph_feature = []\n",
    "    for transcription_id in dataset:       \n",
    "        with open(path / f\"{transcription_id}.txt\", \"r\") as graph_file:\n",
    "            edges = []\n",
    "            for line in graph_file:\n",
    "                parts = line.split()\n",
    "                source, relation, target = int(parts[0]), parts[1], int(parts[2])\n",
    "                edges.append((source, target, {'relation': relation}))\n",
    "            \n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(edges)\n",
    "        # 提取图特征（这里使用节点的度作为特征）\n",
    "        node_degrees = dict(G.degree())\n",
    "        graph_feature += list(node_degrees.values())\n",
    "    \n",
    "    return graph_feature\n",
    "\n",
    "\n",
    "def get_label(dataset, label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as file:\n",
    "        all_labels = json.load(file)\n",
    "    for transcription_id in dataset:  \n",
    "        labels += all_labels[transcription_id]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naive_baseline: \n",
    "##### all utterances are predicted important (label 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3079913606911447\n"
     ]
    }
   ],
   "source": [
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "y_validate = get_label(validate_set, \"training_labels.json\")\n",
    "y_pred = [1] * len(y_validate)\n",
    "\n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text_baseline(Decision Tree): \n",
    "##### utterances are embedded with SentenceTransformer, then train a Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698c38d9c39d4ecf8c82f0d37b1bf49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfc2598570c4166998f3c0065f3fc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38149063935005295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "X_training = get_text_feature(training_set, path_to_training)\n",
    "y_training = get_label(training_set, \"training_labels.json\")\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "X_validate = get_text_feature(validate_set, path_to_training, show_progress_bar=False)\n",
    "y_validate = get_label(validate_set, \"training_labels.json\")\n",
    "\n",
    "y_pred = clf.predict(X_validate).tolist()\n",
    "\n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text_baseline(Random Forest): \n",
    "##### utterances are embedded with SentenceTransformer, then train a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe4b61e98c474fbf04b1e78adc5dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25344036697247707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "X_training = get_text_feature(training_set, path_to_training)\n",
    "y_training = get_label(training_set, \"training_labels.json\")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=5, criterion='gini', n_jobs=-1, random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "X_validate = get_text_feature(validate_set, path_to_training, show_progress_bar=False)\n",
    "y_validate = get_label(validate_set, \"training_labels.json\")\n",
    "\n",
    "y_pred = clf.predict(X_validate).tolist()\n",
    "\n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42511c49ac434ec28f52782df827858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n_estimators=100 and max_depth=10\n",
      "Running with n_estimators=100 and max_depth=20\n",
      "Running with n_estimators=200 and max_depth=10\n",
      "Running with n_estimators=200 and max_depth=20\n",
      "Running with n_estimators=300 and max_depth=10\n",
      "Running with n_estimators=300 and max_depth=20\n",
      "best_score:  0.26552706552706556\n",
      "best_parameter:  [100, 20]\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "X_training = get_text_feature(training_set, path_to_training)\n",
    "y_training = get_label(training_set, \"training_labels.json\")\n",
    "\n",
    "best_score = 0\n",
    "for n_estimators in [20, 35, 50, 75]:\n",
    "    for max_depth in [25, 30, 35]:\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion='gini', n_jobs=-1, random_state=0)\n",
    "        clf.fit(X_training, y_training)\n",
    "\n",
    "        X_validate = get_text_feature(validate_set, path_to_training, show_progress_bar=False)\n",
    "        y_validate = get_label(validate_set, \"training_labels.json\")\n",
    "\n",
    "        y_pred = clf.predict(X_validate).tolist()\n",
    "        \n",
    "        score = f1_score(y_validate, y_pred, average='binary')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameter = [n_estimators, max_depth]\n",
    "\n",
    "# print F1 score\n",
    "print(\"best_score: \", best_score)\n",
    "print(\"best_parameter: \", best_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine_baseline(Random Forest): \n",
    "##### utterances are embedded with SentenceTransformer, node degrees are used as graph feature, then train a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5efed1e2e64a989d8c1bae44251161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3808854532677442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "train_text_feature = get_text_feature(training_set, path_to_training)\n",
    "train_graph_feature = get_graph_feature(training_set, path_to_training)\n",
    "X_training = [np.concatenate((text_feat, [graph_feat])) for text_feat, graph_feat in zip(train_text_feature, train_graph_feature)]\n",
    "y_training = get_label(training_set, \"training_labels.json\")\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "validate_text_feature = get_text_feature(validate_set, path_to_training, show_progress_bar=False)\n",
    "validate_graph_feature = get_graph_feature(validate_set, path_to_training)\n",
    "X_validate = [np.concatenate((text_feat, [graph_feat])) for text_feat, graph_feat in zip(validate_text_feature, validate_graph_feature)]\n",
    "y_validate = get_label(validate_set, \"training_labels.json\")\n",
    "\n",
    "y_pred = clf.predict(X_validate).tolist()\n",
    "\n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
