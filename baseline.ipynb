{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split training and test sets of transcription ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def flatten(list_of_list):\n",
    "    return [item for sublist in list_of_list for item in sublist]\n",
    "\n",
    "path_to_training = Path(\"training\")\n",
    "path_to_test = Path(\"test\")\n",
    "\n",
    "def split_dataset(validate=False):\n",
    "    training_set = ['ES2002', 'ES2005', 'ES2006', 'ES2007', 'ES2008', 'ES2009', 'ES2010', 'ES2012', 'ES2013', 'ES2015', 'ES2016', 'IS1000', 'IS1001', 'IS1002', 'IS1003', 'IS1004', 'IS1005', 'IS1006', 'IS1007', 'TS3005', 'TS3008', 'TS3009', 'TS3010', 'TS3011', 'TS3012']\n",
    "    training_set = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in training_set])\n",
    "    training_set.remove('IS1002a')\n",
    "    training_set.remove('IS1005d')\n",
    "    training_set.remove('TS3012c')\n",
    "\n",
    "    test_set = ['ES2003', 'ES2004', 'ES2011', 'ES2014', 'IS1008', 'IS1009', 'TS3003', 'TS3004', 'TS3006', 'TS3007']\n",
    "    test_set = flatten([[m_id+s_id for s_id in 'abcd'] for m_id in test_set])\n",
    "    \n",
    "    if validate:\n",
    "        # randomly select 10% of training set as validation set\n",
    "        import random\n",
    "        random.seed(6969)\n",
    "        validate_set = random.choices(training_set, k=int(len(training_set)*0.1))\n",
    "        training_set = list(set(training_set) - set(validate_set))\n",
    "        return training_set, validate_set, test_set\n",
    "\n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naive_baseline: \n",
    "##### all utterances are predicted important (label 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3079913606911447\n"
     ]
    }
   ],
   "source": [
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "y_validate, y_pred = [], []\n",
    "with open(\"training_labels.json\", \"r\") as file:\n",
    "    training_labels = json.load(file)\n",
    "for transcription_id in validate_set:  \n",
    "    y_validate += training_labels[transcription_id]\n",
    "    y_pred += [1] * len(training_labels[transcription_id])\n",
    "\n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text_baseline(Decision Tree): \n",
    "##### utterances are embedded with SentenceTransformer, then train a Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e3d943c8664d739e21f1e7c1b2b015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3863235812477969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "y_training = []\n",
    "with open(\"training_labels.json\", \"r\") as file:\n",
    "    training_labels = json.load(file)\n",
    "X_training = []\n",
    "for transcription_id in training_set:\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    for utterance in transcription:\n",
    "        X_training.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    y_training += training_labels[transcription_id]\n",
    "\n",
    "X_training = bert.encode(X_training, show_progress_bar=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "y_pred, y_validate = [], []\n",
    "for transcription_id in validate_set:\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    X_validate = []\n",
    "    for utterance in transcription:\n",
    "        X_validate.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    y_validate += training_labels[transcription_id]\n",
    "    \n",
    "    X_validate = bert.encode(X_validate)\n",
    "\n",
    "    y_pred += clf.predict(X_validate).tolist()\n",
    "\n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text_baseline(Random Forest): \n",
    "##### utterances are embedded with SentenceTransformer, then train a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe4b61e98c474fbf04b1e78adc5dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25344036697247707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "y_training = []\n",
    "with open(\"training_labels.json\", \"r\") as file:\n",
    "    training_labels = json.load(file)\n",
    "X_training = []\n",
    "for transcription_id in training_set:\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    for utterance in transcription:\n",
    "        X_training.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    y_training += training_labels[transcription_id]\n",
    "\n",
    "X_training = bert.encode(X_training, show_progress_bar=True)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=250, max_depth=5, criterion='gini', n_jobs=-1, random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "y_pred, y_validate = [], []\n",
    "for transcription_id in validate_set:\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    X_validate = []\n",
    "    for utterance in transcription:\n",
    "        X_validate.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    y_validate += training_labels[transcription_id]\n",
    "    \n",
    "    X_validate = bert.encode(X_validate)\n",
    "\n",
    "    y_pred += clf.predict(X_validate).tolist()\n",
    "\n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42511c49ac434ec28f52782df827858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n_estimators=100 and max_depth=10\n",
      "Running with n_estimators=100 and max_depth=20\n",
      "Running with n_estimators=200 and max_depth=10\n",
      "Running with n_estimators=200 and max_depth=20\n",
      "Running with n_estimators=300 and max_depth=10\n",
      "Running with n_estimators=300 and max_depth=20\n",
      "best_score:  0.26552706552706556\n",
      "best_parameter:  [100, 20]\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "y_training = []\n",
    "with open(\"training_labels.json\", \"r\") as file:\n",
    "    training_labels = json.load(file)\n",
    "X_training = []\n",
    "for transcription_id in training_set:\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    for utterance in transcription:\n",
    "        X_training.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    y_training += training_labels[transcription_id]\n",
    "\n",
    "X_training = bert.encode(X_training, show_progress_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n_estimators=20 and max_depth=25\n",
      "Running with n_estimators=20 and max_depth=30\n",
      "Running with n_estimators=20 and max_depth=35\n",
      "Running with n_estimators=35 and max_depth=25\n",
      "Running with n_estimators=35 and max_depth=30\n",
      "Running with n_estimators=35 and max_depth=35\n",
      "Running with n_estimators=50 and max_depth=25\n",
      "Running with n_estimators=50 and max_depth=30\n",
      "Running with n_estimators=50 and max_depth=35\n",
      "Running with n_estimators=75 and max_depth=25\n",
      "Running with n_estimators=75 and max_depth=30\n",
      "Running with n_estimators=75 and max_depth=35\n",
      "best_score:  0.3201621073961499\n",
      "best_parameter:  [20, 25]\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for n_estimators in [20, 35, 50, 75]:\n",
    "    for max_depth in [25, 30, 35]:\n",
    "        print(f'Running with n_estimators={n_estimators} and max_depth={max_depth}')\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion='gini', n_jobs=-1, random_state=0)\n",
    "        clf.fit(X_training, y_training)\n",
    "\n",
    "        y_pred, y_validate = [], []\n",
    "        for transcription_id in validate_set:\n",
    "            with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "                transcription = json.load(file)\n",
    "            \n",
    "            X_validate = []\n",
    "            for utterance in transcription:\n",
    "                X_validate.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "            \n",
    "            y_validate += training_labels[transcription_id]\n",
    "            \n",
    "            X_validate = bert.encode(X_validate)\n",
    "\n",
    "            y_pred += clf.predict(X_validate).tolist()\n",
    "        \n",
    "        score = f1_score(y_validate, y_pred, average='binary')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameter = [n_estimators, max_depth]\n",
    "\n",
    "# print F1 score\n",
    "print(\"best_score: \", best_score)\n",
    "print(\"best_parameter: \", best_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine_baseline(Random Forest): \n",
    "##### utterances are embedded with SentenceTransformer, node degrees are used as graph feature, then train a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f52fca356fb49f085e7dc5330518a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "X has 384 features, but RandomForestClassifier is expecting 385 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6232\\2807673907.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mX_validate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# print F1 score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\17269\\.conda\\envs\\ml7\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m--> 808\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\17269\\.conda\\envs\\ml7\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\17269\\.conda\\envs\\ml7\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\17269\\.conda\\envs\\ml7\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\17269\\.conda\\envs\\ml7\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             raise ValueError(\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 384 features, but RandomForestClassifier is expecting 385 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "training_set, validate_set, test_set = split_dataset(validate=True)\n",
    "\n",
    "y_training = []\n",
    "with open(\"training_labels.json\", \"r\") as file:\n",
    "    training_labels = json.load(file)\n",
    "train_text_feature, train_graph_feature = [], []\n",
    "for transcription_id in training_set:\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as text_file:\n",
    "        transcription = json.load(text_file)\n",
    "    \n",
    "    for utterance in transcription:\n",
    "        train_text_feature.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "        \n",
    "    with open(path_to_training / f\"{transcription_id}.txt\", \"r\") as graph_file:\n",
    "        edges = []\n",
    "        for line in graph_file:\n",
    "            parts = line.split()\n",
    "            source, relation, target = int(parts[0]), parts[1], int(parts[2])\n",
    "            edges.append((source, target, {'relation': relation}))\n",
    "        \n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    # 提取图特征（这里使用节点的度作为特征）\n",
    "    node_degrees = dict(G.degree())\n",
    "    train_graph_feature += list(node_degrees.values())\n",
    "    \n",
    "    y_training += training_labels[transcription_id]\n",
    "\n",
    "train_text_feature = bert.encode(train_text_feature, show_progress_bar=True)\n",
    "X_training = [np.concatenate((text_feat, [graph_feat])) for text_feat, graph_feat in zip(train_text_feature, train_graph_feature)]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=250, criterion='gini', n_jobs=-1, random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "y_pred, y_validate = [], []\n",
    "for transcription_id in validate_set:\n",
    "    validate_text_feature = []\n",
    "    with open(path_to_training / f\"{transcription_id}.json\", \"r\") as file:\n",
    "        transcription = json.load(file)\n",
    "    \n",
    "    for utterance in transcription:\n",
    "        validate_text_feature.append(utterance[\"speaker\"] + \": \" + utterance[\"text\"])\n",
    "    \n",
    "    with open(path_to_training / f\"{transcription_id}.txt\", \"r\") as graph_file:\n",
    "        edges = []\n",
    "        for line in graph_file:\n",
    "            parts = line.split()\n",
    "            source, relation, target = int(parts[0]), parts[1], int(parts[2])\n",
    "            edges.append((source, target, {'relation': relation}))\n",
    "        \n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    node_degrees = dict(G.degree())\n",
    "    validate_graph_feature = list(node_degrees.values())\n",
    "    \n",
    "    validate_text_feature = bert.encode(validate_text_feature)\n",
    "    X_validate = [np.concatenate((text_feat, [graph_feat])) for text_feat, graph_feat in zip(validate_text_feature, validate_graph_feature)]\n",
    "\n",
    "    y_pred += clf.predict(X_validate).tolist()\n",
    "    y_validate += training_labels[transcription_id]\n",
    "    \n",
    "# print F1 score\n",
    "print(f1_score(y_validate, y_pred, average='binary'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
